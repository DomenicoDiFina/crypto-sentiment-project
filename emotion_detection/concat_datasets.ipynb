{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0e8cf27ca7fe1f44572ebd606cffb3470dda0dafe0d98156262796b51af03dddc",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pickle\n",
    "from pre_processing import pre_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df_preprocessed_1.sav', 'rb') as f:\n",
    "   tweet_processed = pickle.load(f)\n",
    "\n",
    "with open('df_preprocessed_2.sav', 'rb') as f:\n",
    "   content_processed = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_worry_1 = pd.read_csv('../dataset/worry_df.csv', delimiter='\\t', header=None, names=['id', 'tweet', 'sentiment', 'value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_worry_2 = pd.read_csv('../dataset/worry_df_2.csv', delimiter='\\t', header=None, names=['id', 'tweet', 'sentiment', 'value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   tweet sentiment\n",
       "0      @noblebIack maribel: a girl that is sweet and ...      love\n",
       "1        @james_blue_cat Loving the his and his handbag.      love\n",
       "2      Loving #treatyouright by @thejunglegiants righ...      love\n",
       "4      Happy Birthday Fabulous Shaun Wallace. Brillia...      love\n",
       "5      We are loving this beautiful sunshine. My OM10...      love\n",
       "...                                                  ...       ...\n",
       "19995        @EricNewcomer Loving this European coverage      love\n",
       "19996  Are you loving Chainsaw Man? Comment below wit...      love\n",
       "19997  Happy #Oscars Week! Will NEVER stop loving thi...      love\n",
       "19998  @shonasongs @MaryBlackSinger Ah the great Noel...      love\n",
       "19999  @LeslieKMercer1 @TheDoobieBros we so need to c...      love\n",
       "\n",
       "[19693 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@noblebIack maribel: a girl that is sweet and ...</td>\n      <td>love</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@james_blue_cat Loving the his and his handbag.</td>\n      <td>love</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Loving #treatyouright by @thejunglegiants righ...</td>\n      <td>love</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Happy Birthday Fabulous Shaun Wallace. Brillia...</td>\n      <td>love</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>We are loving this beautiful sunshine. My OM10...</td>\n      <td>love</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19995</th>\n      <td>@EricNewcomer Loving this European coverage</td>\n      <td>love</td>\n    </tr>\n    <tr>\n      <th>19996</th>\n      <td>Are you loving Chainsaw Man? Comment below wit...</td>\n      <td>love</td>\n    </tr>\n    <tr>\n      <th>19997</th>\n      <td>Happy #Oscars Week! Will NEVER stop loving thi...</td>\n      <td>love</td>\n    </tr>\n    <tr>\n      <th>19998</th>\n      <td>@shonasongs @MaryBlackSinger Ah the great Noel...</td>\n      <td>love</td>\n    </tr>\n    <tr>\n      <th>19999</th>\n      <td>@LeslieKMercer1 @TheDoobieBros we so need to c...</td>\n      <td>love</td>\n    </tr>\n  </tbody>\n</table>\n<p>19693 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "df_love = pd.read_csv('../dataset/love.csv')\n",
    "df_love = df_love[df_love['language'] == 'en']\n",
    "df_love = df_love.loc[:,['tweet']]\n",
    "df_love['sentiment'] = 'love'\n",
    "df_love"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   tweet sentiment\n",
       "0      We're sad to update that a body has been found...   sadness\n",
       "1           Sad news to report   https://t.co/giZcBKSNly   sadness\n",
       "2      @PChrisDavid They were desperate for it to kic...   sadness\n",
       "4      @SPAJournalism Aww shucks guys, thank you! Sad...   sadness\n",
       "5      This is incredibly sad, and frustrating. The Q...   sadness\n",
       "...                                                  ...       ...\n",
       "19995  User centered reporting delights me every time...   sadness\n",
       "19996  Remember this one time the lowly #Rockies were...   sadness\n",
       "19997                 @JudgyJoodz I'm more sad than mad.   sadness\n",
       "19998  Help I just went into Ample Hills sobbing and ...   sadness\n",
       "19999  Deepest condolences on the sad demise of Times...   sadness\n",
       "\n",
       "[18118 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>We're sad to update that a body has been found...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sad news to report   https://t.co/giZcBKSNly</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@PChrisDavid They were desperate for it to kic...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@SPAJournalism Aww shucks guys, thank you! Sad...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>This is incredibly sad, and frustrating. The Q...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19995</th>\n      <td>User centered reporting delights me every time...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>19996</th>\n      <td>Remember this one time the lowly #Rockies were...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>19997</th>\n      <td>@JudgyJoodz I'm more sad than mad.</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>19998</th>\n      <td>Help I just went into Ample Hills sobbing and ...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>19999</th>\n      <td>Deepest condolences on the sad demise of Times...</td>\n      <td>sadness</td>\n    </tr>\n  </tbody>\n</table>\n<p>18118 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "df_sad = pd.read_csv('../dataset/sad.csv')\n",
    "df_sad = df_sad[df_sad['language'] == 'en']\n",
    "df_sad = df_sad.loc[:,['tweet']]\n",
    "df_sad['sentiment'] = 'sadness'\n",
    "df_sad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\domy-\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (9) have mixed types.Specify dtype option on import or set low_memory=False.\n  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   tweet sentiment\n",
       "0      Deep breaths, staying active and getting outsi...     worry\n",
       "1      #KaranMehra- #NishaRawal Case: While #ManveerG...     worry\n",
       "2      THE PRESSURE IS ON FLOYDðŸ˜‰  The Maverick isn't ...     worry\n",
       "3      â€œOfficials are worried about fleeting contact ...     worry\n",
       "4      The Victorian Government is worried about a ne...     worry\n",
       "...                                                  ...       ...\n",
       "19995  'Iâ€™m worried we now risk turning the clock bac...     worry\n",
       "19996  Worried about people who need to be out and ab...     worry\n",
       "19997  Bulldog? I really think they are having a dig....     worry\n",
       "19998  @MZanona @SenatorSinema whereâ€™s this shot take...     worry\n",
       "19999  How worried should we be about new variants fo...     worry\n",
       "\n",
       "[19967 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Deep breaths, staying active and getting outsi...</td>\n      <td>worry</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>#KaranMehra- #NishaRawal Case: While #ManveerG...</td>\n      <td>worry</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>THE PRESSURE IS ON FLOYDðŸ˜‰  The Maverick isn't ...</td>\n      <td>worry</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>â€œOfficials are worried about fleeting contact ...</td>\n      <td>worry</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The Victorian Government is worried about a ne...</td>\n      <td>worry</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19995</th>\n      <td>'Iâ€™m worried we now risk turning the clock bac...</td>\n      <td>worry</td>\n    </tr>\n    <tr>\n      <th>19996</th>\n      <td>Worried about people who need to be out and ab...</td>\n      <td>worry</td>\n    </tr>\n    <tr>\n      <th>19997</th>\n      <td>Bulldog? I really think they are having a dig....</td>\n      <td>worry</td>\n    </tr>\n    <tr>\n      <th>19998</th>\n      <td>@MZanona @SenatorSinema whereâ€™s this shot take...</td>\n      <td>worry</td>\n    </tr>\n    <tr>\n      <th>19999</th>\n      <td>How worried should we be about new variants fo...</td>\n      <td>worry</td>\n    </tr>\n  </tbody>\n</table>\n<p>19967 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "df_worry = pd.read_csv('../dataset/worry.csv')\n",
    "df_worry = df_worry[df_worry['language'] == 'en']\n",
    "df_worry = df_worry.loc[:,['tweet']]\n",
    "df_worry['sentiment'] = 'worry'\n",
    "df_worry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   tweet  sentiment\n",
       "0      Happy birthday  #SonakshiSinha keep rocking !!...  happiness\n",
       "1      Exhibitions are more important than ever! We w...  happiness\n",
       "2      @JeevanK28113885 Hi there, we're sorry to hear...  happiness\n",
       "3      @Lexosborne44 Hi Lexie, happy to help. Please ...  happiness\n",
       "5      @justneil Hi Neil, Please can you pop over a D...  happiness\n",
       "...                                                  ...        ...\n",
       "19994  Absolute legends. Happy #WorldMilkDay to our a...  happiness\n",
       "19995  @Lucy_K_Author Happy paperback publication day...  happiness\n",
       "19996  Happy Birthday @Normani! ðŸ‘‘ Practicing this tod...  happiness\n",
       "19997  @orIandorafael Good afternoon. I apologize for...  happiness\n",
       "19999              @Dorianlynskey Happy birthday Dorian!  happiness\n",
       "\n",
       "[18631 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Happy birthday  #SonakshiSinha keep rocking !!...</td>\n      <td>happiness</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Exhibitions are more important than ever! We w...</td>\n      <td>happiness</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@JeevanK28113885 Hi there, we're sorry to hear...</td>\n      <td>happiness</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@Lexosborne44 Hi Lexie, happy to help. Please ...</td>\n      <td>happiness</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>@justneil Hi Neil, Please can you pop over a D...</td>\n      <td>happiness</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19994</th>\n      <td>Absolute legends. Happy #WorldMilkDay to our a...</td>\n      <td>happiness</td>\n    </tr>\n    <tr>\n      <th>19995</th>\n      <td>@Lucy_K_Author Happy paperback publication day...</td>\n      <td>happiness</td>\n    </tr>\n    <tr>\n      <th>19996</th>\n      <td>Happy Birthday @Normani! ðŸ‘‘ Practicing this tod...</td>\n      <td>happiness</td>\n    </tr>\n    <tr>\n      <th>19997</th>\n      <td>@orIandorafael Good afternoon. I apologize for...</td>\n      <td>happiness</td>\n    </tr>\n    <tr>\n      <th>19999</th>\n      <td>@Dorianlynskey Happy birthday Dorian!</td>\n      <td>happiness</td>\n    </tr>\n  </tbody>\n</table>\n<p>18631 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "df_happy = pd.read_csv('../dataset/happy.csv')\n",
    "df_happy = df_happy[df_happy['language'] == 'en']\n",
    "df_happy = df_happy.loc[:,['tweet']]\n",
    "df_happy['sentiment'] = 'happiness'\n",
    "df_happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   tweet sentiment\n",
       "0      'When this hot, hermetic noise coming from fou...   neutral\n",
       "1      Only 30% of everyday Nigerians are dissatisfie...   neutral\n",
       "2      â€œAn aware and assertive citizenry, in contradi...   neutral\n",
       "3      I think most people are good people. Not in th...   neutral\n",
       "4      The eyes on the street supposedly failed Genov...   neutral\n",
       "...                                                  ...       ...\n",
       "19995  *shares indifferent Eminem opinion*  https://t...   neutral\n",
       "19996  @RealAlexCerone @BWildeRecrutes This. Bad mana...   neutral\n",
       "19997  @jmjones The best part was the confused/indiff...   neutral\n",
       "19998  @DrewChamplin @TimbersFC @MLS @LAGalaxy Ah. Th...   neutral\n",
       "19999  Reaction in #Patriots locker room to Roger Goo...   neutral\n",
       "\n",
       "[18252 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>'When this hot, hermetic noise coming from fou...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Only 30% of everyday Nigerians are dissatisfie...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>â€œAn aware and assertive citizenry, in contradi...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I think most people are good people. Not in th...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The eyes on the street supposedly failed Genov...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19995</th>\n      <td>*shares indifferent Eminem opinion*  https://t...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>19996</th>\n      <td>@RealAlexCerone @BWildeRecrutes This. Bad mana...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>19997</th>\n      <td>@jmjones The best part was the confused/indiff...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>19998</th>\n      <td>@DrewChamplin @TimbersFC @MLS @LAGalaxy Ah. Th...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>19999</th>\n      <td>Reaction in #Patriots locker room to Roger Goo...</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n<p>18252 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 125
    }
   ],
   "source": [
    "df_neutral = pd.read_csv('../dataset/neutral.csv')\n",
    "df_neutral = df_neutral[df_neutral['language'] == 'en']\n",
    "df_neutral = df_neutral.loc[:,['tweet']]\n",
    "df_neutral['sentiment'] = 'neutral'\n",
    "df_neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_worry_1 = df_worry_1.loc[:,['tweet', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_worry_2 = df_worry_2.loc[:,['tweet', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Processing tweets:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19967/19967 [00:03<00:00, 5484.47it/s]\n",
      "word tokenize process: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19967/19967 [25:42<00:00, 12.95it/s]\n",
      "Remove stop word: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19967/19967 [00:12<00:00, 1604.66it/s]\n"
     ]
    }
   ],
   "source": [
    "tweets = pre_processing(list(df_worry['tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Processing tweets:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 995/995 [00:00<00:00, 6953.16it/s]\n",
      "word tokenize process: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 995/995 [00:55<00:00, 17.82it/s]\n",
      "Remove stop word: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 995/995 [00:00<00:00, 1737.91it/s]\n"
     ]
    }
   ],
   "source": [
    "tweets_2 = pre_processing(list(df_worry_2['tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Processing tweets:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19693/19693 [00:03<00:00, 6104.77it/s]\n",
      "word tokenize process: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19693/19693 [21:53<00:00, 14.99it/s]\n",
      "Remove stop word: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19693/19693 [00:11<00:00, 1664.92it/s]\n"
     ]
    }
   ],
   "source": [
    "tweets_3 = pre_processing(list(df_love['tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Processing tweets:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18118/18118 [00:02<00:00, 6187.27it/s]\n",
      "word tokenize process: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18118/18118 [20:55<00:00, 14.44it/s]\n",
      "Remove stop word: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18118/18118 [00:11<00:00, 1645.44it/s]\n"
     ]
    }
   ],
   "source": [
    "tweets_4 = pre_processing(list(df_sad['tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Processing tweets:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1147/1147 [00:00<00:00, 2621.87it/s]\n",
      "word tokenize process: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1147/1147 [01:29<00:00, 12.79it/s]\n",
      "Remove stop word: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1147/1147 [00:01<00:00, 1116.62it/s]\n"
     ]
    }
   ],
   "source": [
    "tweets_5 = pre_processing(list(df_worry_1['tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Processing tweets:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18252/18252 [00:01<00:00, 9268.38it/s]\n",
      "word tokenize process: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18252/18252 [1:06:13<00:00,  4.59it/s]\n",
      "Remove stop word: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18252/18252 [00:13<00:00, 1370.04it/s]\n"
     ]
    }
   ],
   "source": [
    "tweets_6 = pre_processing(list(df_neutral['tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Processing tweets:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18631/18631 [00:04<00:00, 3784.61it/s]\n",
      "word tokenize process: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18631/18631 [27:33<00:00, 11.27it/s]\n",
      "Remove stop word: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18631/18631 [00:07<00:00, 2456.89it/s]\n"
     ]
    }
   ],
   "source": [
    "tweets_7 = pre_processing(list(df_happy['tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = pd.DataFrame({'tweets':tweets, 'emotion': df_worry['sentiment']})\n",
    "df_tweets['emotion'] = df_tweets['emotion'].replace('fear', 'worry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_2 = pd.DataFrame({'tweets':tweets_2, 'emotion': df_worry_2['sentiment']})\n",
    "df_tweets_2['emotion'] = df_tweets_2['emotion'].replace('fear', 'worry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_3 = pd.DataFrame({'tweets':tweets_3, 'emotion': df_love['sentiment']})\n",
    "df_tweets_4 = pd.DataFrame({'tweets':tweets_4, 'emotion': df_sad['sentiment']})\n",
    "df_tweets_5 = pd.DataFrame({'tweets':tweets_5, 'emotion': df_worry_1['sentiment']})\n",
    "df_tweets_6 = pd.DataFrame({'tweets':tweets_6, 'emotion': df_neutral['sentiment']})\n",
    "df_tweets_7 = pd.DataFrame({'tweets':tweets_7, 'emotion': df_happy['sentiment']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                  tweets    emotion\n",
       "1        [layin, n, bed, headache, ughhhh, waitin, call]    sadness\n",
       "2                    [funeral, ceremony, gloomy, friday]    sadness\n",
       "3                           [wants, hang, friends, soon]  happiness\n",
       "4          [want, trade, someone, houston, tickets, one]    neutral\n",
       "5             [pinging, go, prom, bc, bf, like, friends]      worry\n",
       "...                                                  ...        ...\n",
       "19994  [absolute, legends, happy, worldmilkday, amazi...  happiness\n",
       "19995  [happy, paperback, publication, day, lucy, loo...  happiness\n",
       "19996        [happy, birthday, practicing, today, honor]  happiness\n",
       "19997  [good, afternoon, apologize, wifi, trouble, ex...  happiness\n",
       "19999                          [happy, birthday, dorian]  happiness\n",
       "\n",
       "[155766 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweets</th>\n      <th>emotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>[layin, n, bed, headache, ughhhh, waitin, call]</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[funeral, ceremony, gloomy, friday]</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[wants, hang, friends, soon]</td>\n      <td>happiness</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[want, trade, someone, houston, tickets, one]</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[pinging, go, prom, bc, bf, like, friends]</td>\n      <td>worry</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19994</th>\n      <td>[absolute, legends, happy, worldmilkday, amazi...</td>\n      <td>happiness</td>\n    </tr>\n    <tr>\n      <th>19995</th>\n      <td>[happy, paperback, publication, day, lucy, loo...</td>\n      <td>happiness</td>\n    </tr>\n    <tr>\n      <th>19996</th>\n      <td>[happy, birthday, practicing, today, honor]</td>\n      <td>happiness</td>\n    </tr>\n    <tr>\n      <th>19997</th>\n      <td>[good, afternoon, apologize, wifi, trouble, ex...</td>\n      <td>happiness</td>\n    </tr>\n    <tr>\n      <th>19999</th>\n      <td>[happy, birthday, dorian]</td>\n      <td>happiness</td>\n    </tr>\n  </tbody>\n</table>\n<p>155766 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 128
    }
   ],
   "source": [
    "dataset_emotion = pd.concat([tweet_processed, content_processed, df_tweets, df_tweets_2, df_tweets_3, df_tweets_4, df_tweets_5, df_tweets_6, df_tweets_7])\n",
    "dataset_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                         tokenized_tweets    emotion  \\\n",
       "0         [layin, n, bed, headache, ughhhh, waitin, call]    sadness   \n",
       "1                     [funeral, ceremony, gloomy, friday]    sadness   \n",
       "2                            [wants, hang, friends, soon]  happiness   \n",
       "3           [want, trade, someone, houston, tickets, one]    neutral   \n",
       "4              [pinging, go, prom, bc, bf, like, friends]      worry   \n",
       "...                                                   ...        ...   \n",
       "155761  [absolute, legends, happy, worldmilkday, amazi...  happiness   \n",
       "155762  [happy, paperback, publication, day, lucy, loo...  happiness   \n",
       "155763        [happy, birthday, practicing, today, honor]  happiness   \n",
       "155764  [good, afternoon, apologize, wifi, trouble, ex...  happiness   \n",
       "155765                          [happy, birthday, dorian]  happiness   \n",
       "\n",
       "                                                processed  \n",
       "0                 layin n bed headache ughhhh waitin call  \n",
       "1                          funeral ceremony gloomy friday  \n",
       "2                                 wants hang friends soon  \n",
       "3                  want trade someone houston tickets one  \n",
       "4                      pinging go prom bc bf like friends  \n",
       "...                                                   ...  \n",
       "155761  absolute legends happy worldmilkday amazing da...  \n",
       "155762  happy paperback publication day lucy look pret...  \n",
       "155763              happy birthday practicing today honor  \n",
       "155764  good afternoon apologize wifi trouble experien...  \n",
       "155765                              happy birthday dorian  \n",
       "\n",
       "[155766 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokenized_tweets</th>\n      <th>emotion</th>\n      <th>processed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[layin, n, bed, headache, ughhhh, waitin, call]</td>\n      <td>sadness</td>\n      <td>layin n bed headache ughhhh waitin call</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[funeral, ceremony, gloomy, friday]</td>\n      <td>sadness</td>\n      <td>funeral ceremony gloomy friday</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[wants, hang, friends, soon]</td>\n      <td>happiness</td>\n      <td>wants hang friends soon</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[want, trade, someone, houston, tickets, one]</td>\n      <td>neutral</td>\n      <td>want trade someone houston tickets one</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[pinging, go, prom, bc, bf, like, friends]</td>\n      <td>worry</td>\n      <td>pinging go prom bc bf like friends</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>155761</th>\n      <td>[absolute, legends, happy, worldmilkday, amazi...</td>\n      <td>happiness</td>\n      <td>absolute legends happy worldmilkday amazing da...</td>\n    </tr>\n    <tr>\n      <th>155762</th>\n      <td>[happy, paperback, publication, day, lucy, loo...</td>\n      <td>happiness</td>\n      <td>happy paperback publication day lucy look pret...</td>\n    </tr>\n    <tr>\n      <th>155763</th>\n      <td>[happy, birthday, practicing, today, honor]</td>\n      <td>happiness</td>\n      <td>happy birthday practicing today honor</td>\n    </tr>\n    <tr>\n      <th>155764</th>\n      <td>[good, afternoon, apologize, wifi, trouble, ex...</td>\n      <td>happiness</td>\n      <td>good afternoon apologize wifi trouble experien...</td>\n    </tr>\n    <tr>\n      <th>155765</th>\n      <td>[happy, birthday, dorian]</td>\n      <td>happiness</td>\n      <td>happy birthday dorian</td>\n    </tr>\n  </tbody>\n</table>\n<p>155766 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 129
    }
   ],
   "source": [
    "dataset_emotion = dataset_emotion.reset_index(drop=True)\n",
    "dataset_emotion['processed'] = dataset_emotion['tweets'].apply(lambda x: ' '.join(map(str,x)))\n",
    "dataset_emotion.rename(columns={'tweets': 'tokenized_tweets'}, inplace=True)\n",
    "dataset_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "happiness    35371\n",
       "sadness      33208\n",
       "worry        31944\n",
       "neutral      26746\n",
       "love         25171\n",
       "surprise      2179\n",
       "fear          1147\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 130
    }
   ],
   "source": [
    "dataset_emotion[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_emotion = dataset_emotion[dataset_emotion['emotion'] != 'surprise']\n",
    "dataset_emotion = dataset_emotion[dataset_emotion['emotion'] != 'fear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "happiness    35371\n",
       "sadness      33208\n",
       "worry        31944\n",
       "neutral      26746\n",
       "love         25171\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "dataset_emotion[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset_emotion_preprocessed_augmented.pickle', 'wb') as f:\n",
    "   pickle.dump(dataset_emotion, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset_emotion_preprocessed.pickle', 'rb') as f:\n",
    "   dataset_emotion = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                        tokenized_tweets    emotion  \\\n",
       "0        [layin, n, bed, headache, ughhhh, waitin, call]    sadness   \n",
       "1                    [funeral, ceremony, gloomy, friday]    sadness   \n",
       "2                           [wants, hang, friends, soon]  happiness   \n",
       "3          [want, trade, someone, houston, tickets, one]    neutral   \n",
       "4             [pinging, go, prom, bc, bf, like, friends]      worry   \n",
       "...                                                  ...        ...   \n",
       "58958  [brief, time, beanbag, said, anna, feel, like,...    sadness   \n",
       "58959  [turning, feel, pathetic, still, waiting, tabl...    sadness   \n",
       "58960                      [feel, strong, good, overall]  happiness   \n",
       "58961              [feel, like, rude, comment, im, glad]    sadness   \n",
       "58962                 [know, lot, feel, stupid, portray]    sadness   \n",
       "\n",
       "                                               processed  \n",
       "0                layin n bed headache ughhhh waitin call  \n",
       "1                         funeral ceremony gloomy friday  \n",
       "2                                wants hang friends soon  \n",
       "3                 want trade someone houston tickets one  \n",
       "4                     pinging go prom bc bf like friends  \n",
       "...                                                  ...  \n",
       "58958      brief time beanbag said anna feel like beaten  \n",
       "58959  turning feel pathetic still waiting tables sub...  \n",
       "58960                           feel strong good overall  \n",
       "58961                     feel like rude comment im glad  \n",
       "58962                       know lot feel stupid portray  \n",
       "\n",
       "[58963 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokenized_tweets</th>\n      <th>emotion</th>\n      <th>processed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[layin, n, bed, headache, ughhhh, waitin, call]</td>\n      <td>sadness</td>\n      <td>layin n bed headache ughhhh waitin call</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[funeral, ceremony, gloomy, friday]</td>\n      <td>sadness</td>\n      <td>funeral ceremony gloomy friday</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[wants, hang, friends, soon]</td>\n      <td>happiness</td>\n      <td>wants hang friends soon</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[want, trade, someone, houston, tickets, one]</td>\n      <td>neutral</td>\n      <td>want trade someone houston tickets one</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[pinging, go, prom, bc, bf, like, friends]</td>\n      <td>worry</td>\n      <td>pinging go prom bc bf like friends</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>58958</th>\n      <td>[brief, time, beanbag, said, anna, feel, like,...</td>\n      <td>sadness</td>\n      <td>brief time beanbag said anna feel like beaten</td>\n    </tr>\n    <tr>\n      <th>58959</th>\n      <td>[turning, feel, pathetic, still, waiting, tabl...</td>\n      <td>sadness</td>\n      <td>turning feel pathetic still waiting tables sub...</td>\n    </tr>\n    <tr>\n      <th>58960</th>\n      <td>[feel, strong, good, overall]</td>\n      <td>happiness</td>\n      <td>feel strong good overall</td>\n    </tr>\n    <tr>\n      <th>58961</th>\n      <td>[feel, like, rude, comment, im, glad]</td>\n      <td>sadness</td>\n      <td>feel like rude comment im glad</td>\n    </tr>\n    <tr>\n      <th>58962</th>\n      <td>[know, lot, feel, stupid, portray]</td>\n      <td>sadness</td>\n      <td>know lot feel stupid portray</td>\n    </tr>\n  </tbody>\n</table>\n<p>58963 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "dataset_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}