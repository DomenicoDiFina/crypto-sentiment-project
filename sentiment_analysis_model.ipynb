{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "venv",
      "display_name": "Python 3.8.5  ('venv': venv)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "source": [
        "Import library"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "from pre_processing import pre_processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "i7mQiVOhV6hF"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /home/s4lv0/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /home/s4lv0/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# Import dataset from: https://www.kaggle.com/kazanova/sentiment140"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('../dataset_sentiment_analysis.csv', names=[\"sentiment\", \"id\", \"date\", \"query\", \"user\", \"tweet\"])"
      ]
    },
    {
      "source": [
        "# View information about dataset"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dim dataset:  1600000\n",
            "Unique sentiment:  [0 4]\n",
            "Number of null elements in columns:\n",
            " sentiment    0\n",
            "id           0\n",
            "date         0\n",
            "query        0\n",
            "user         0\n",
            "tweet        0\n",
            "dtype: int64\n",
            "Percentuage of positive tweets:  50.0 %\n",
            "Percentuage of negative tweets:  50.0 %\n"
          ]
        }
      ],
      "source": [
        "print(\"Dim dataset: \", len(dataset))\n",
        "print(\"Unique sentiment: \", dataset[\"sentiment\"].unique())\n",
        "\n",
        "#check if dataset contain any null values in sentiment and tweet\n",
        "print(\"Number of null elements in columns:\\n\", dataset.isnull().sum())\n",
        "\n",
        "#view number of positive and negative tweets\n",
        "print(\"Percentuage of positive tweets: \", (len(dataset[\"sentiment\"][dataset.sentiment == 4])/len(dataset))*100, \"%\")\n",
        "print(\"Percentuage of negative tweets: \", (len(dataset[\"sentiment\"][dataset.sentiment == 0])/len(dataset))*100, \"%\")"
      ]
    },
    {
      "source": [
        "# Dataset manipulation:\n",
        "- Drop unnecessary information (id, date, query, user)\n",
        "- Replace sentiment id from 0,4 (negative, positive) to 0,1 (negative, positive)\n",
        "- convert column tweet from object to str"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New shape of dataset:  (1600000, 2)\n"
          ]
        }
      ],
      "source": [
        "#shuffle dataset\n",
        "#dataset = dataset.sample(frac=1)\n",
        "#drop unnecessary information\n",
        "dataset.drop([\"id\", \"date\", \"query\", \"user\"], axis=1, inplace=True)\n",
        "#replace sentiment id\n",
        "dataset[\"sentiment\"].replace(4,1)\n",
        "\n",
        "#convert tweet from object to str\n",
        "dataset[\"tweet\"] = dataset[\"tweet\"].astype(\"str\")\n",
        "\n",
        "print(\"New shape of dataset: \", dataset.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing tweets:: 100%|██████████| 1600000/1600000 [01:20<00:00, 19758.31it/s]\n",
            "word tokenize process: 100%|██████████| 1600000/1600000 [02:31<00:00, 10534.67it/s]\n",
            "Remove stop word: 100%|██████████| 1600000/1600000 [03:02<00:00, 8751.38it/s]\n"
          ]
        }
      ],
      "source": [
        "processing_tweet = pre_processing(list(dataset[\"tweet\"]))"
      ]
    },
    {
      "source": [
        "Convert tokenized tweet from list to str"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset[\"processed_tweet\"] = processing_tweet\n",
        "dataset[\"processed_tweet\"] = dataset['processed_tweet'].apply(lambda x: ' '.join(map(str,x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sentiment                                              tweet  \\\n0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n1          0  is upset that he can't update his Facebook by ...   \n2          0  @Kenichan I dived many times for the ball. Man...   \n3          0    my whole body feels itchy and like its on fire    \n4          0  @nationwideclass no, it's not behaving at all....   \n5          0                      @Kwesidei not the whole crew    \n6          0                                        Need a hug    \n7          0  @LOLTrish hey  long time no see! Yes.. Rains a...   \n8          0               @Tatiana_K nope they didn't have it    \n9          0                          @twittera que me muera ?    \n\n                                     processed_tweet  \n0       awww bummer shoulda got david carr third day  \n1  upset update facebook texting might cry result...  \n2  dived many times ball managed save 50 rest go ...  \n3                   whole body feels itchy like fire  \n4                                   behaving mad see  \n5                                         whole crew  \n6                                           need hug  \n7  hey long time see yes rains bit bit laughing l...  \n8                                               nope  \n9                                          que muera  \n"
          ]
        }
      ],
      "source": [
        "print(dataset[:][:10])"
      ]
    },
    {
      "source": [
        "# Save dataset to pickle file\n",
        "### warning: save dataset produce a file dim: ~250mb"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "#shuffle dataset\n",
        "dataset = dataset.sample(frac=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "files = open(\"dataset_sentiment_analysis.pickle\", \"wb\")\n",
        "pickle.dump(dataset, files)\n"
      ]
    },
    {
      "source": [
        "# Creating ML model using LSTM\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset.columns\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000, split=' ')\n",
        "\n",
        "tokenizer.fit_on_texts(dataset['processed_tweet'].values)\n",
        "\n",
        "X = tokenizer.texts_to_sequences(dataset['processed_tweet'])\n",
        "\n",
        "X = pad_sequences(X)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "files = open(\"tokenizer.pickle\", \"wb\")\n",
        "pickle.dump(tokenizer, files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 48, 300)           1500000   \n_________________________________________________________________\nspatial_dropout1d (SpatialDr (None, 48, 300)           0         \n_________________________________________________________________\nlstm (LSTM)                  (None, 196)               389648    \n_________________________________________________________________\ndense (Dense)                (None, 2)                 394       \n=================================================================\nTotal params: 1,890,042\nTrainable params: 1,890,042\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
          ]
        }
      ],
      "source": [
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(5000, 300,input_length = X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(2,activation='sigmoid'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop',metrics = ['accuracy'])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y = pd.get_dummies(dataset['sentiment']).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.20, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1280000, 48) (1280000, 2)\n(320000, 48) (320000, 2)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape,y_train.shape)\n",
        "print(X_test.shape,y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1280000\n"
          ]
        }
      ],
      "source": [
        "print(len(X_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(0, len(X_train)-320000, 320000):\n",
        "    print(i)\n",
        "    model.fit(X_train[i:i+320000], y_train[i:i+320000], epochs=10, batch_size = 64, verbose = 1)\n",
        "    model.evaluate(X_test, y_test, verbose=1)\n",
        "    print(\"******* SAVING MODEL *******\")\n",
        "    model.save(\"sentiment_model_lstm\")"
      ]
    },
    {
      "source": [
        "model.fit(X_train, y_train, epochs=10, batch_size = 64, verbose = 1)\n",
        "print(\"***** EVALUATION *****\")\n",
        "model.evaluate(X_test, y_test, verbose=1)"
      ],
      "cell_type": "code",
      "metadata": {},
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "  179/20000 [..............................] - ETA: 51:43 - loss: 0.4767 - accuracy: 0.7720"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-16b54cc49711>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"***** EVALUATION *****\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/web_data_project/venv/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/web_data_project/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/web_data_project/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/web_data_project/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/web_data_project/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m~/Desktop/web_data_project/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/web_data_project/venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = load_model(\"sentiment_model_lstm\")"
      ]
    }
  ]
}